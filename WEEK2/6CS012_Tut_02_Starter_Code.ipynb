{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **About the Notebook:**\n","### **Softmax Regression with in ERM Framework.**\n","\n","This notebook contains all the code presented in the slides. Please run the code as we progress\n"],"metadata":{"id":"wd8WslZUfy5C"}},{"cell_type":"markdown","source":["## Understanding Data:\n","\n","Dataset Used = iris.csv"],"metadata":{"id":"NR6yC2CdgP95"}},{"cell_type":"code","source":["# Necessary Imports\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import matplotlib.pyplot as plt"],"metadata":{"id":"Mboqc-p1iiOt","executionInfo":{"status":"ok","timestamp":1741075097565,"user_tz":-345,"elapsed":2914,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/Iris.csv\") # changed to read_csv and the correct file name\n","# Step 2: Dataset Information\n","print(\"Dataset Preview:\")\n","print(df.head())  # Show first 5 rows\n","print(\"\\nDataset Information:\")\n","print(df.info())  # Summary of dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"ICWNUFa5ipGp","outputId":"b2fe4134-2b39-4795-bed9-095c08db5d74","executionInfo":{"status":"error","timestamp":1741075098324,"user_tz":-345,"elapsed":784,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/Iris.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-07f17d77a5d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Iris.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# changed to read_csv and the correct file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Step 2: Dataset Information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset Preview:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Show first 5 rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDataset Information:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Iris.csv'"]}]},{"cell_type":"code","source":["# Step 3: Extract features (X) and target labels (y)\n","X = df.iloc[:, 1:-1].values  # All columns except the first and the last one (features) since the first column is an index\n","y = df.iloc[:, -1].values   # Last column (target)\n","\n","# Step 4: Convert categorical labels to numeric\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)  # Convert labels to integers (0,1,2)\n","\n","# Step 5: One-Hot Encode the Labels\n","one_hot_encoder = OneHotEncoder(sparse_output=False) #changed sparse to sparse_output and set to False\n","y_one_hot = one_hot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n","\n","# Display results\n","print(\"\\nUnique Classes:\", np.unique(y))\n","print(\"Encoded Labels:\", np.unique(y_encoded))\n","print(\"One-Hot Encoded Labels:\\n\", y_one_hot[:5])  # Show first 5"],"metadata":{"id":"ECYML_3ni40E","executionInfo":{"status":"aborted","timestamp":1741075098481,"user_tz":-345,"elapsed":2,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Split dataset into training (80%) and testing (20%) sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot)\n","\n","# Output shapes\n","print(\"\\nShapes:\")\n","print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n","print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"],"metadata":{"id":"o8_kzmrRi7XC","executionInfo":{"status":"aborted","timestamp":1741075098485,"user_tz":-345,"elapsed":1,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decision Function or Model."],"metadata":{"id":"YmSZUGKImFC7"}},{"cell_type":"code","source":["import numpy as np\n","\n","def softmax(z):\n","    \"\"\"\n","    Compute the softmax probabilities for a given input matrix.\n","\n","    Parameters:\n","    z (numpy.ndarray): Logits (raw scores) of shape (m, n), where\n","                       - m is the number of samples.\n","                       - n is the number of classes.\n","\n","    Returns:\n","    numpy.ndarray: Softmax probability matrix of shape (m, n), where\n","                   each row sums to 1 and represents the probability\n","                   distribution over classes.\n","\n","    Notes:\n","    - The input to softmax is typically computed as: z = XW + b.\n","    - Uses numerical stabilization by subtracting the max value per row.\n","    \"\"\"\n","\n","    # Prevent numerical instability by normalizing input\n","    z_shifted = z - np.max(z, axis=1, keepdims=True)\n","    exp_z = np.exp(z_shifted)\n","    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n"],"metadata":{"id":"WAG8uFYIiNJo","executionInfo":{"status":"aborted","timestamp":1741075098487,"user_tz":-345,"elapsed":0,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implement Loss and Cost Function:"],"metadata":{"id":"Rv7J9p-GnTdG"}},{"cell_type":"markdown","source":["## Loss Function:"],"metadata":{"id":"V4QKvpJLosA0"}},{"cell_type":"code","source":["import numpy as np\n","\n","def loss_softmax(y_pred, y):\n","    \"\"\"\n","    Compute the cross-entropy loss.\n","\n","    Parameters:\n","    y_pred (numpy.ndarray): Predicted probabilities of shape (n, c), where n is the number of samples and c is the number of classes.\n","    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n","\n","    Returns:\n","    float: Cross-entropy loss.\n","    \"\"\"\n","    epsilon = 1e-12  # To avoid log(0)\n","    y_pred = np.clip(y_pred, epsilon, 1.0 - epsilon)  # Prevent log(0) by clipping values\n","    n = y.shape[0]  # Number of samples\n","    loss = -np.sum(y * np.log(y_pred)) / n\n","    return loss\n"],"metadata":{"id":"s5Kon-WBl29w","executionInfo":{"status":"aborted","timestamp":1741075098489,"user_tz":-345,"elapsed":4217,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cost Function:"],"metadata":{"id":"3uGO56_7oyT7"}},{"cell_type":"code","source":["def cost_softmax(X, y, W, b):\n","    \"\"\"\n","    Compute the softmax regression cost (cross-entropy loss).\n","\n","    Parameters:\n","    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n","    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c), where c is the number of classes.\n","    W (numpy.ndarray): Weight matrix of shape (d, c).\n","    b (numpy.ndarray): Bias vector of shape (c,).\n","\n","    Returns:\n","    float: The softmax cost (cross-entropy loss).\n","    \"\"\"\n","    n = X.shape[0]  # Number of samples\n","    z = np.dot(X, W) + b\n","    y_pred = softmax(z)\n","    cost = loss_softmax(y_pred, y)\n","    return cost"],"metadata":{"id":"rgM4tyj1nXsM","executionInfo":{"status":"aborted","timestamp":1741075098492,"user_tz":-345,"elapsed":1,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implement Optimization with Gradient Descent:"],"metadata":{"id":"XgwqA5H0o3N8"}},{"cell_type":"markdown","source":["### Compute the Gradients:"],"metadata":{"id":"RFoIFkyPo8R0"}},{"cell_type":"code","source":["def compute_gradient_softmax(X, y, W, b):\n","    \"\"\"\n","    Compute the gradients of the cost function with respect to weights and biases.\n","\n","    Parameters:\n","    X (numpy.ndarray): Feature matrix of shape (n, d).\n","    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n","    W (numpy.ndarray): Weight matrix of shape (d, c).\n","    b (numpy.ndarray): Bias vector of shape (c,).\n","\n","    Returns:\n","    tuple: Gradients with respect to weights (d, c) and biases (c,).\n","    \"\"\"\n","    n, d = X.shape\n","    z = np.dot(X, W) + b\n","    y_pred = softmax(z)\n","\n","    grad_W = np.dot(X.T, (y_pred - y)) / n  # Gradient with respect to weights\n","    grad_b = np.sum(y_pred - y, axis=0) / n  # Gradient with respect to biases\n","\n","    return grad_W, grad_b\n"],"metadata":{"id":"_sWRIh4Po2Kx","executionInfo":{"status":"aborted","timestamp":1741075098494,"user_tz":-345,"elapsed":2,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Perform Gradient Descent:"],"metadata":{"id":"-Cy_GhxrpBTz"}},{"cell_type":"code","source":["def gradient_descent_softmax(X, y, W, b, alpha, n_iter, show_cost=False):\n","    \"\"\"\n","    Perform gradient descent to optimize the weights and biases.\n","\n","    Parameters:\n","    X (numpy.ndarray): Feature matrix of shape (n, d).\n","    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n","    W (numpy.ndarray): Weight matrix of shape (d, c).\n","    b (numpy.ndarray): Bias vector of shape (c,).\n","    alpha (float): Learning rate.\n","    n_iter (int): Number of iterations.\n","    show_cost (bool): Whether to display the cost at intervals.\n","\n","    Returns:\n","    tuple: Optimized weights, biases, and cost history.\n","    \"\"\"\n","    cost_history = []\n","\n","    for i in range(n_iter):\n","        # Compute gradients\n","        grad_W, grad_b = compute_gradient_softmax(X, y, W, b)\n","\n","        # Update weights and biases using the gradients\n","        W -= alpha * grad_W\n","        b -= alpha * grad_b\n","\n","        # Compute and store cost\n","        cost = cost_softmax(X, y, W, b)\n","        cost_history.append(cost)\n","\n","        # Print cost at regular intervals\n","        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n","            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n","\n","    return W, b, cost_history\n"],"metadata":{"id":"ZgRM2qUnpAZc","executionInfo":{"status":"aborted","timestamp":1741075098495,"user_tz":-345,"elapsed":4221,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prediction Function:"],"metadata":{"id":"sT-VTQ5hpbbL"}},{"cell_type":"code","source":["def predict_softmax(X, W, b):\n","    \"\"\"\n","    Predict the class labels for a set of samples using the trained softmax model.\n","\n","    Parameters:\n","    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n","    W (numpy.ndarray): Weight matrix of shape (d, c), where c is the number of classes.\n","    b (numpy.ndarray): Bias vector of shape (c,).\n","\n","    Returns:\n","    numpy.ndarray: Predicted class labels of shape (n,), where each value is the index of the predicted class.\n","    \"\"\"\n","    z = np.dot(X, W) + b  # Compute the scores (logits)\n","    y_pred = softmax(z)  # Get the probabilities using the softmax function\n","\n","    # Assign the class with the highest probability\n","    predicted_classes = np.argmax(y_pred, axis=1)\n","\n","    return predicted_classes"],"metadata":{"id":"_cv4tQbGpGAn","executionInfo":{"status":"aborted","timestamp":1741075098498,"user_tz":-345,"elapsed":1,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the weights and biases\n","d = X_train.shape[1]  # Number of features\n","c = y_train.shape[1]  # Number of classes\n","W = np.random.randn(d, c) * 0.01  # Small random weights\n","b = np.zeros(c)  # Bias initialized to 0\n","\n","# Set hyperparameters\n","alpha = 0.1  # Learning rate\n","n_iter = 1000  # Number of iterations\n","\n","# Train the model using gradient descent\n","W_opt, b_opt, cost_history = gradient_descent_softmax(X_train, y_train, W, b, alpha, n_iter, show_cost=True)\n","\n","# Plot the cost history to visualize the convergence\n","plt.plot(cost_history)\n","plt.title('Cost Function vs. Iterations')\n","plt.xlabel('Iterations')\n","plt.ylabel('Cost')\n","plt.grid(True)\n","plt.show()\n","\n","# Predict on the test set\n","#y_pred_test = predict_softmax(X_test, W_opt, b_opt)\n","\n","# Evaluate accuracy\n","#y_test_labels = np.argmax(y_test, axis=1)  # True labels in numeric form\n","#accuracy = np.mean(y_pred_test == y_test_labels)\n","#print(f\"Test accuracy: {accuracy * 100:.2f}%\")"],"metadata":{"id":"OILFcTSspedj","executionInfo":{"status":"aborted","timestamp":1741075098529,"user_tz":-345,"elapsed":27,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluting the Model."],"metadata":{"id":"cSufnlq4y0B7"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n","\n","# Evaluation Function\n","def evaluate_classification(y_true, y_pred):\n","    \"\"\"\n","    Evaluate classification performance using confusion matrix, precision, recall, and F1-score.\n","\n","    Parameters:\n","    y_true (numpy.ndarray): True labels\n","    y_pred (numpy.ndarray): Predicted labels\n","\n","    Returns:\n","    tuple: Confusion matrix, precision, recall, F1 score\n","    \"\"\"\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    # Compute precision, recall, and F1-score\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","    return cm, precision, recall, f1\n","\n","# Predict on the test set\n","y_pred_test = predict_softmax(X_test, W_opt, b_opt)\n","# Evaluate accuracy\n","y_test_labels = np.argmax(y_test, axis=1)  # True labels in numeric form\n","\n","# Evaluate the model\n","cm, precision, recall, f1 = evaluate_classification(y_test_labels, y_pred_test)\n","\n","# Print the evaluation metrics\n","print(\"\\nConfusion Matrix:\")\n","print(cm)\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","\n","# Visualizing the Confusion Matrix\n","fig, ax = plt.subplots(figsize=(6, 6))\n","cax = ax.imshow(cm, cmap='Blues')  # Use a color map for better visualization\n","\n","# Set tick labels for the axes\n","ax.set_xticks(range(3))\n","ax.set_yticks(range(3))\n","ax.set_xticklabels([f'Predicted {i}' for i in range(3)])\n","ax.set_yticklabels([f'Actual {i}' for i in range(3)])\n","\n","# Add labels to each cell in the confusion matrix\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > np.max(cm) / 2 else 'black')\n","\n","# Add grid lines and axis labels\n","ax.grid(False)\n","plt.title('Confusion Matrix', fontsize=14)\n","plt.xlabel('Predicted Label', fontsize=12)\n","plt.ylabel('Actual Label', fontsize=12)\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.colorbar(cax)\n","plt.show()\n"],"metadata":{"id":"jw-eR5mBy38R","executionInfo":{"status":"aborted","timestamp":1741075098531,"user_tz":-345,"elapsed":4250,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Limitations of Logistic Regression:**"],"metadata":{"id":"RrU34PIBcS2y"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_circles\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","\n","# Step 1: Generate a synthetic non-linear dataset using make_circles\n","X, y = make_circles(n_samples=1000, factor=0.5, noise=0.1)\n","\n","# Step 2: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Step 3: Fit a logistic regression model\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","\n","# Step 4: Create a meshgrid to plot the decision boundary\n","xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 100),\n","                     np.linspace(X[:, 1].min(), X[:, 1].max(), 100))\n","\n","# Step 5: Predict on the meshgrid points to plot the decision boundary\n","Z = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","\n","# Step 6: Plot the data points and the decision boundary\n","plt.figure(figsize=(8, 6))\n","\n","# Plot the decision boundary\n","plt.contourf(xx, yy, Z, levels=[0, 0.5], cmap='Blues', alpha=0.2)\n","\n","# Plot the training data points\n","plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', edgecolors='k', marker='o', label='Train')\n","plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', edgecolors='k', marker='x', label='Test')\n","\n","plt.title(\"Logistic Regression on Non-linear Data (Circles)\")\n","plt.xlabel(\"Feature 1\")\n","plt.ylabel(\"Feature 2\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"gyhXjtfLq8er","executionInfo":{"status":"aborted","timestamp":1741075098534,"user_tz":-345,"elapsed":4249,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OgICBGkAru9i","executionInfo":{"status":"aborted","timestamp":1741075098538,"user_tz":-345,"elapsed":4252,"user":{"displayName":"Aatiz Ghimire","userId":"13085694884778061614"}}},"execution_count":null,"outputs":[]}]}